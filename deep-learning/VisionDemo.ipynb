{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep learning: vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#load \"Paket.fsx\"\n",
    "Paket.Version [ \"FSharp.Data\", \"3.0\"]\n",
    "#load \"Paket.Generated.Refs.fsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "open System.IO  \n",
    "open FSharp.Data\n",
    "open FSharp.Data.HttpRequestHeaders\n",
    "open FSharp.Data.HttpContentTypes\n",
    " \n",
    "//#load \"subscription.fs\" // Load subscription key\n",
    "\n",
    "module Subscription\n",
    "    let subscriptionKey = \"\"  // TODO: Supply your Azure API key for cognitive services (vision)\n",
    "\n",
    "let uriBase = \"https://westeurope.api.cognitive.microsoft.com/vision/v2.0/analyze\"\n",
    "\n",
    "type VisionApi = \n",
    "  JsonProvider<\"\"\"{\"tags\":[{\"name\":\"music\",\"confidence\":0.98865640163421631},{\"name\":\"guitar\",\"confidence\":0.95694917440414429},{\"name\":\"building material\",\"confidence\":0.41293439269065857},{\"name\":\"lumber\",\"confidence\":0.29446199536323547},{\"name\":\"bass\",\"confidence\":0.26204556226730347,\"hint\":\"object\"}],\"description\":{\"tags\":[\"road\",\"building\",\"outdoor\",\"street\",\"night\",\"black\",\"city\",\"white\",\"light\",\"sitting\",\"riding\",\"man\",\"side\",\"empty\",\"rain\",\"corner\",\"traffic\",\"lit\",\"hydrant\",\"stop\",\"board\",\"parked\",\"bus\",\"tall\"],\"captions\":[{\"text\":\"a close up of an empty city street at night\",\"confidence\":0.7965622853462756}]},\"requestId\":\"ad111816-5803-4176-a3a0-0aa59b517db6\",\"metadata\":{\"width\":604,\"height\":271,\"format\":\"Jpeg\"}}\"\"\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "let getPictureDescription imageFilePath = \n",
    "    let bytes = File.ReadAllBytes imageFilePath\n",
    "    let requestParameters = \"visualFeatures=Tags,Description\"\n",
    "    let res = \n",
    "        Http.RequestString(uriBase + \"?\" + requestParameters, \n",
    "                           headers = [ \"Ocp-Apim-Subscription-Key\", Subscription.subscriptionKey\n",
    "                                       ContentType Binary ],\n",
    "                           body = HttpRequestBody.BinaryUpload bytes)\n",
    "    let jsonObject = VisionApi.Parse res\n",
    "    \n",
    "    let description = jsonObject.Description.Captions.[0].Text\n",
    "    let tags = jsonObject.Tags |> Array.map (fun t -> t.Name, t.Confidence)\n",
    "    \n",
    "    printfn \"%s\\n------------------------------\" description\n",
    "    tags |> Array.iter (fun (name, p) -> printfn \"%s: %.3f\" name p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/guitar.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a close up of a guitar\n",
       "------------------------------\n",
       "music: 0.986\n",
       "guitar: 0.958\n",
       "musical instrument: 0.957\n",
       "string instrument: 0.521\n",
       "building material: 0.387\n",
       "lumber: 0.273\n",
       "bass: 0.242\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getPictureDescription \"img/guitar.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](img/monkey1.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a monkey sitting on a table\n",
       "------------------------------\n",
       "primate: 1.000\n",
       "animal: 1.000\n",
       "mammal: 1.000\n",
       "monkey: 0.994\n",
       "sitting: 0.942\n",
       "macaque: 0.883\n",
       "old world monkey: 0.877\n",
       "new world monkey: 0.852\n",
       "rhesus macaque: 0.805\n",
       "baboon: 0.663\n",
       "japanese macaque: 0.646\n",
       "langur: 0.583\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getPictureDescription \"img/monkey1.jpeg\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](img/monkey2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a monkey sitting on a branch\n",
       "------------------------------\n",
       "tree: 0.999\n",
       "outdoor: 0.991\n",
       "primate: 0.988\n",
       "mammal: 0.985\n",
       "animal: 0.985\n",
       "monkey: 0.845\n",
       "new world monkey: 0.789\n",
       "old world monkey: 0.722\n",
       "macaque: 0.712\n",
       "rhesus macaque: 0.547\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getPictureDescription \"img/monkey2.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Out of sample example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](img/smeal.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a close up of a fish\n",
       "------------------------------\n",
       "grass: 1.000\n",
       "outdoor: 0.945\n",
       "animal: 0.867\n",
       "eyes: 0.853\n",
       "fish: 0.703\n",
       "face: 0.701\n",
       "close: 0.421\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getPictureDescription \"img/smeal.png\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple image modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](img/gmonkey2.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a monkey holding a guitar\n",
       "------------------------------\n",
       "tree: 1.000\n",
       "guitar: 0.985\n",
       "sky: 0.984\n",
       "outdoor: 0.981\n",
       "musical instrument: 0.955\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getPictureDescription \"img/gmonkey2.jpeg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](img/gmonkey1.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a dog looking at the camera\n",
       "------------------------------\n",
       "indoor: 0.934\n",
       "guitar: 0.898\n",
       "musical instrument: 0.761\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getPictureDescription \"img/gmonkey1.jpeg\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](img/ggmonkey2.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a monkey holding a dog\n",
       "------------------------------\n",
       "tree: 0.999\n",
       "animal: 0.941\n",
       "mammal: 0.930\n",
       "outdoor: 0.892\n",
       "primate: 0.864\n",
       "monkey: 0.608\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getPictureDescription \"img/ggmonkey2.jpeg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What does it see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](img/landscape1.jpg)\n",
    "source: `aiweirdness.com`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a herd of sheep grazing on a lush green hillside\n",
       "------------------------------\n",
       "mountain: 1.000\n",
       "outdoor: 0.999\n",
       "sky: 0.995\n",
       "nature: 0.990\n",
       "grass: 0.970\n",
       "grazing: 0.919\n",
       "landscape: 0.918\n",
       "cloud: 0.912\n",
       "hill: 0.898\n",
       "hillside: 0.859\n",
       "green: 0.859\n",
       "hiking: 0.857\n",
       "fell: 0.839\n",
       "field: 0.815\n",
       "grassy: 0.686\n",
       "hill station: 0.624\n",
       "background: 0.603\n",
       "lush: 0.582\n",
       "mountain range: 0.568\n",
       "pasture: 0.560\n",
       "valley: 0.530\n",
       "ridge: 0.529\n",
       "overlooking: 0.331\n",
       "highland: 0.286\n",
       "distance: 0.122\n",
       "land: 0.106\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getPictureDescription \"img/landscape1.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/office1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a man standing in a room\n",
       "------------------------------\n",
       "indoor: 0.982\n",
       "whiteboard: 0.968\n",
       "floor: 0.960\n",
       "computer: 0.959\n",
       "office building: 0.949\n",
       "furniture: 0.949\n",
       "table: 0.933\n",
       "chair: 0.928\n",
       "person: 0.923\n",
       "desk: 0.921\n",
       "ceiling: 0.839\n",
       "design: 0.825\n",
       "clothing: 0.766\n",
       "text: 0.760\n",
       "laptop: 0.617\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getPictureDescription \"img/office1.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/office1elephant.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a couple of people that are standing in a room\n",
       "------------------------------\n",
       "whiteboard: 0.900\n",
       "furniture: 0.865\n",
       "chair: 0.799\n",
       "computer: 0.776\n",
       "table: 0.718\n",
       "clothing: 0.710\n",
       "text: 0.672\n",
       "person: 0.590\n",
       "design: 0.532\n",
       "desk: 0.532\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getPictureDescription \"img/office1elephant.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](img/monkey2elephant.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a monkey sitting on a branch\n",
       "------------------------------\n",
       "tree: 1.000\n",
       "animal: 0.988\n",
       "outdoor: 0.986\n",
       "mammal: 0.985\n",
       "monkey: 0.963\n",
       "primate: 0.819\n",
       "zoo: 0.561\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getPictureDescription \"img/monkey2elephant.jpeg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# AI Surrealism\n",
    "![](img/magritte.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a man wearing a suit and hat\n",
       "------------------------------\n",
       "man: 0.998\n",
       "person: 0.997\n",
       "suit: 0.979\n",
       "cartoon: 0.964\n",
       "wearing: 0.964\n",
       "painting: 0.958\n",
       "fashion accessory: 0.942\n",
       "fedora: 0.916\n",
       "green: 0.841\n",
       "jacket: 0.823\n",
       "hat: 0.818\n",
       "human face: 0.813\n",
       "cowboy hat: 0.800\n",
       "sun hat: 0.747\n",
       "drawing: 0.678\n",
       "clothing: 0.577\n",
       "tie: 0.543\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getPictureDescription \"img/magritte.jpg\""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "F#",
   "language": "fsharp",
   "name": "ifsharp"
  },
  "language": "fsharp",
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".fs",
   "mimetype": "text/x-fsharp",
   "name": "fsharp",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "4.3.1.0"
  },
  "rise": {
   "center": true,
   "enable_chalkboard": false,
   "scroll": true,
   "theme": "white",
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
